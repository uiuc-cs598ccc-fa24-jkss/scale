@inproceedings{comdist23,
    author = {C. Eder and S. Winzinger and R. Lichtenthaler},
    booktitle = {2023 IEEE International Conference on Service-Oriented System Engineering (SOSE)},
    title = {A Comparison of Distributed Tracing Tools in Serverless Applications},
    year = {2023},
    volume = {},
    issn = {},
    pages = {98-105},
    abstract = {Serverless computing can favor the emergence of complex and error-prone applications. In order to gain observability in such applications, distributed tracing can be used. However, as serverless computing relies on the pay-per-use billing model, utilizing distributed tracing tools can have a noticeable impact on the resulting costs. Therefore, this paper investigates the impact of distributed tracing in serverless applications by exploring and comparing the efficiency characteristics of three selected distributed tracing tools - Zipkin, OpenTelemetry, and SkyWalking. In particular, the runtime, the memory usage, and the initialization duration were examined by benchmarking AWS Lambda function invocations. In the experiments, Zipkin imposed the lowest runtime overhead with an average of 10.73 %, while SkyWalking introduced the highest overhead with an average runtime overhead of 50.67 %. OpenTelemetry added 24.19 % additional runtime. Besides runtime overheads, significantly higher memory usage and initialization durations were detected for all tools. Therefore, the results suggest that distributed tracing can significantly impact the efficiency of serverless applications. Nevertheless, differences could be observed concerning tracing mechanisms and use cases. This helps developers to carefully select the most suitable tracing tool considering factors such as runtime overhead, memory usage, and initialization durations.},
    keywords = {computer languages;runtime;costs;service-oriented systems engineering;computational modeling;instruments;serverless computing},
    doi = {10.1109/SOSE58276.2023.00018},
    url = {https://doi.ieeecomputersociety.org/10.1109/SOSE58276.2023.00018},
    publisher = {IEEE Computer Society},
    address = {Los Alamitos, CA, USA},
    month = {jul}
}

@inproceedings{powpred22,
    author = {Luo, Shutian and Xu, Huanle and Ye, Kejiang and Xu, Guoyao and Zhang, Liping and Yang, Guodong and Xu, Chengzhong},
    title = {The power of prediction: microservice auto scaling via workload learning},
    year = {2022},
    isbn = {9781450394147},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3542929.3563477},
    doi = {10.1145/3542929.3563477},
    abstract = {When deploying microservices in production clusters, it is critical to automatically scale containers to improve cluster utilization and ensure service level agreements (SLA). Although reactive scaling approaches work well for monolithic architectures, they are not necessarily suitable for microservice frameworks due to the long delay caused by complex microservice call chains. In contrast, existing proactive approaches leverage end-to-end performance prediction for scaling, but cannot effectively handle microservice multiplexing and dynamic microservice dependencies.In this paper, we present Madu, a proactive microservice auto-scaler that scales containers based on predictions for individual microservices. Madu learns workload uncertainty to handle the highly dynamic dependency between microservices. Additionally, Madu adopts OS-level metrics to optimize resource usage while maintaining good control over scaling overhead. Experiments on large-scale deployments of microservices in Alibaba clusters show that the overall prediction accuracy of Madu can reach as high as 92.3\% on average, which is 13\% higher than the state-of-the-art approaches. Furthermore, experiments running real-world microservice benchmarks in a local cluster of 20 servers show that Madu can reduce the overall resource usage by 1.7X compared to reactive solutions, while reducing end-to-end service latency by 50\%.},
    booktitle = {Proceedings of the 13th Symposium on Cloud Computing},
    pages = {355–369},
    numpages = {15},
    keywords = {workload uncertainty learning, proactive auto-scaler, microservices},
    location = {San Francisco, California},
    series = {SoCC '22}
}

@inproceedings{alibab21,
    author = {Luo, Shutian and Xu, Huanle and Lu, Chengzhi and Ye, Kejiang and Xu, Guoyao and Zhang, Liping and Ding, Yu and He, Jian and Xu, Chengzhong},
    title = {Characterizing Microservice Dependency and Performance: Alibaba Trace Analysis},
    year = {2021},
    isbn = {9781450386388},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3472883.3487003},
    doi = {10.1145/3472883.3487003},
    abstract = {Loosely-coupled and light-weight microservices running in containers are replacing monolithic applications gradually. Understanding the characteristics of microservices is critical to make good use of microservice architectures. However, there is no comprehensive study about microservice and its related systems in production environments so far. In this paper, we present a solid analysis of large-scale deployments of microservices at Alibaba clusters. Our study focuses on the characterization of microservice dependency as well as its runtime performance. We conduct an in-depth anatomy of microservice call graphs to quantify the difference between them and traditional DAGs of data-parallel jobs. In particular, we observe that microservice call graphs are heavy-tail distributed and their topology is similar to a tree and moreover, many microservices are hot-spots. We reveal three types of meaningful call dependency that can be utilized to optimize microservice designs. Our investigation on microservice runtime performance indicates most microservices are much more sensitive to CPU interference than memory interference. To synthesize more representative microservice traces, we build a mathematical model to simulate call graphs. Experimental results demonstrate our model can well preserve those graph properties observed from Alibaba traces.},
    booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
    pages = {412–426},
    numpages = {15},
    location = {Seattle, WA, USA},
    series = {SoCC '21}
}

@inproceedings{whysolve22,
    author = {Straesser, Martin and Grohmann, Johannes and von Kistowski, J\'{o}akim and Eismann, Simon and Bauer, Andr\'{e} and Kounev, Samuel},
    title = {Why Is It Not Solved Yet? Challenges for Production-Ready Autoscaling},
    year = {2022},
    isbn = {9781450391436},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3489525.3511680},
    doi = {10.1145/3489525.3511680},
    abstract = {Autoscaling is a task of major importance in the cloud computing domain as it directly affects both operating costs and customer experience. Although there has been active research in this area for over ten years now, there is still a significant gap between the proposed methods in the literature and the deployed autoscalers in practice. Hence, many research autoscalers do not find their way into production deployments. This paper describes six core challenges that arise in production systems that are still not solved by most research autoscalers. We illustrate these problems through experiments in a realistic cloud environment with a real-world multi-service business application and show that commonly used autoscalers have various shortcomings. In addition, we analyze the behavior of overloaded services and show that these can be problematic for existing autoscalers. Generally, we analyze that these challenges are only insufficiently addressed in the literature and conclude that future scaling approaches should focus on the needs of production systems.},
    booktitle = {Proceedings of the 2022 ACM/SPEC on International Conference on Performance Engineering},
    pages = {105–115},
    numpages = {11},
    keywords = {microservices, cloud computing, autoscaling},
    location = {Beijing, China},
    series = {ICPE '22}
}

@inproceedings{deepflow23,
    author = {Shen, Junxian and Zhang, Han and Xiang, Yang and Shi, Xingang and Li, Xinrui and Shen, Yunxi and Zhang, Zijian and Wu, Yongxiang and Yin, Xia and Wang, Jilong and Xu, Mingwei and Li, Yahui and Yin, Jiping and Song, Jianchang and Li, Zhuofeng and Nie, Runjie},
    title = {Network-Centric Distributed Tracing with DeepFlow: Troubleshooting Your Microservices in Zero Code},
    year = {2023},
    isbn = {9798400702365},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3603269.3604823},
    doi = {10.1145/3603269.3604823},
    abstract = {Microservices are becoming more complicated, posing new challenges for traditional performance monitoring solutions. On the one hand, the rapid evolution of microservices places a significant burden on the utilization and maintenance of existing distributed tracing frameworks. On the other hand, complex infrastructure increases the probability of network performance problems and creates more blind spots on the network side. In this paper, we present DeepFlow, a network-centric distributed tracing framework for troubleshooting microservices. DeepFlow provides out-of-the-box tracing via a network-centric tracing plane and implicit context propagation. In addition, it eliminates blind spots in network infrastructure, captures network metrics in a low-cost way, and enhances correlation between different components and layers. We demonstrate analytically and empirically that DeepFlow is capable of locating microservice performance anomalies with negligible overhead. DeepFlow has already identified over 71 critical performance anomalies for more than 26 companies and has been utilized by hundreds of individual developers. Our production evaluations demonstrate that DeepFlow is able to save users hours of instrumentation efforts and reduce troubleshooting time from several hours to just a few minutes.},
    booktitle = {Proceedings of the ACM SIGCOMM 2023 Conference},
    pages = {420–437},
    numpages = {18},
    keywords = {distributed tracing, application performance monitoring, network performance monitoring, eBPF},
    location = {New York, NY, USA},
    series = {ACM SIGCOMM '23}
}

@inproceedings{mesh21,
    author={Cha, Donghun and Kim, Younghan},
    booktitle={2021 International Conference on Information and Communication Technology Convergence (ICTC)}, 
    title={Service Mesh Based Distributed Tracing System}, 
    year={2021},
    pages={1464-1466},
    keywords={Instruments;Fault detection;Microservice architectures;Distributed databases;Data visualization;Libraries;Information and communication technology;microservice architecture;observability;cloud-native;distributed tracing;container;service mesh},
    doi={10.1109/ICTC52510.2021.9620968}
}

@inproceedings{traceweaver24,
    author = {Ashok, Sachin and Harsh, Vipul and Godfrey, Brighten and Mittal, Radhika and Parthasarathy, Srinivasan and Shwartz, Larisa},
    title = {TraceWeaver: Distributed Request Tracing for Microservices Without Application Modification},
    year = {2024},
    isbn = {9798400706141},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3651890.3672254},
    doi = {10.1145/3651890.3672254},
    abstract = {Monitoring and debugging modern cloud-based applications is challenging since even a single API call can involve many interdependent distributed microservices. To provide observability for such complex systems, distributed tracing frameworks track request flow across the microservice call tree. However, such solutions require instrumenting every component of the distributed application to add and propagate tracing headers, which has slowed adoption. This paper explores whether we can trace requests without any application instrumentation, which we refer to as request trace reconstruction. To that end, we develop TraceWeaver, a system that incorporates readily available information from production settings (e.g., timestamps) and test environments (e.g., call graphs) to reconstruct request traces with usefully high accuracy. At the heart of TraceWeaver is a reconstruction algorithm that uses request-response timestamps to effectively prune the search space for mapping requests and applies statistical timing analysis techniques to reconstruct traces. Evaluation with (1) benchmark microservice applications and (2) a production microservice dataset demonstrates that TraceWeaver can achieve a high accuracy of ~90\% and can be meaningfully applied towards multiple use cases (e.g., finding slow services and A/B testing).},
    booktitle = {Proceedings of the ACM SIGCOMM 2024 Conference},
    pages = {828–842},
    numpages = {15},
    keywords = {non-intrusive, distributed tracing, graph analysis, microservices},
    location = {Sydney, NSW, Australia},
    series = {ACM SIGCOMM '24}
}

@misc{astraea24,
    title={An Online Probabilistic Distributed Tracing System},
    author={M. Toslali and S. Qasim and S. Parthasarathy and F. A. Oliveira and H. Huang and G. Stringhini and Z. Liu and A. K. Coskun},
    year={2024},
    eprint={2405.15645},
    archivePrefix={arXiv},
    primaryClass={cs.PF}
}

@inproceedings{latenseer23,
    author = {Zhang, Yazhuo and Isaacs, Rebecca and Yue, Yao and Yang, Juncheng and Zhang, Lei and Vigfusson, Ymir},
    title = {LatenSeer: Causal Modeling of End-to-End Latency Distributions by Harnessing Distributed Tracing},
    year = {2023},
    isbn = {9798400703874},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3620678.3624787},
    doi = {10.1145/3620678.3624787},
    abstract = {End-to-end latency estimation in web applications is crucial for system operators to foresee the effects of potential changes, helping ensure system stability, optimize cost, and improve user experience. However, estimating latency in microservices-based architectures is challenging due to the complex interactions between hundreds or thousands of loosely coupled microservices. Current approaches either track only latency-critical paths or require laborious bespoke instrumentation, which is unrealistic for end-to-end latency estimation in complex systems.This paper presents LatenSeer, a modeling framework for estimating end-to-end latency distributions in microservice-based web applications. LatenSeer proposes novel data structures to accurately represent causal relationships between services, overcoming the drawbacks of simple dependency representations that fail to capture the complexity of microservices. LatenSeer leverages distributed tracing data to practically and accurately model end-to-end latency at scale. Our evaluation shows that LatenSeer predicts latency within a 5.35\% error, outperforming the state-of-the-art that has an error rate of more than 9.5\%.},
    booktitle = {Proceedings of the 2023 ACM Symposium on Cloud Computing},
    pages = {502–519},
    numpages = {18},
    keywords = {microservices, latency estimation, end-to-end latency, distributed tracing},
    location = {Santa Cruz, CA, USA},
    series = {SoCC '23}
}

@article{trastrainer24,
    author = {Huang, Haiyu and Zhang, Xiaoyu and Chen, Pengfei and He, Zilong and Chen, Zhiming and Yu, Guangba and Chen, Hongyang and Sun, Chen},
    title = {TraStrainer: Adaptive Sampling for Distributed Traces with System Runtime State},
    year = {2024},
    issue_date = {July 2024},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {1},
    number = {FSE},
    url = {https://doi.org/10.1145/3643748},
    doi = {10.1145/3643748},
    abstract = {Distributed tracing has been widely adopted in many microservice systems and plays an important role in monitoring and analyzing the system. However, trace data often come in large volumes, incurring substantial computational and storage costs. To reduce the quantity of traces, trace sampling has become a prominent topic of discussion, and several methods have been proposed in prior work. To attain higher-quality sampling outcomes, biased sampling has gained more attention compared to random sampling. Previous biased sampling methods primarily considered the importance of traces based on diversity, aiming to sample more edge-case traces and fewer common-case traces. However, we contend that relying solely on trace diversity for sampling is insufficient, system runtime state is another crucial factor that needs to be considered, especially in cases of system failures. In this study, we introduce TraStrainer, an online sampler that takes into account both system runtime state and trace diversity. TraStrainer employs an interpretable and automated encoding method to represent traces as vectors. Simultaneously, it adaptively determines sampling preferences by analyzing system runtime metrics. When sampling, it combines the results of system-bias and diversity-bias through a dynamic voting mechanism. Experimental results demonstrate that TraStrainer can achieve higher quality sampling results and significantly improve the performance of downstream root cause analysis (RCA) tasks. It has led to an average increase of 32.63\% in Top-1 RCA accuracy compared to four baselines in two datasets.},
    journal = {Proc. ACM Softw. Eng.},
    month = {jul},
    articleno = {22},
    numpages = {21},
    keywords = {biased sampling, distributed tracing, microservice}
}

@inproceedings{steam23,
    author = {He, Shilin and Feng, Botao and Li, Liqun and Zhang, Xu and Kang, Yu and Lin, Qingwei and Rajmohan, Saravan and Zhang, Dongmei},
    title = {STEAM: Observability-Preserving Trace Sampling},
    year = {2023},
    isbn = {9798400703270},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3611643.3613881},
    doi = {10.1145/3611643.3613881},
    abstract = {In distributed systems and microservice applications, tracing is a crucial observability signal employed for comprehending their internal states. To mitigate the overhead associated with distributed tracing, most tracing frameworks utilize a uniform sampling strategy, which retains only a subset of traces. However, this approach is insufficient for preserving system observability. This is primarily attributed to the long-tail distribution of traces in practice, which results in the omission or rarity of minority yet critical traces after sampling. In this study, we introduce an observability-preserving trace sampling method, denoted as STEAM, which aims to retain as much information as possible in the sampled traces. We employ Graph Neural Networks (GNN) for trace representation, while incorporating domain knowledge of trace comparison through logical clauses. Subsequently, we employ a scalable approach to sample traces, emphasizing mutually dissimilar traces. STEAM has been implemented on top of OpenTelemetry, comprising approximately 1.6K lines of Golang code and 2K lines of Python code. Evaluation on four benchmark microservice applications and a production system demonstrates the superior performance of our approach compared to baseline methods. Furthermore, STEAM is capable of processing 15,000 traces in approximately 4 seconds.},
    booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
    pages = {1750–1761},
    numpages = {12},
    keywords = {distributed tracing, graph neural network, trace sampling},
    location = {San Francisco, CA, USA},
    series = {ESEC/FSE 2023}
}

@inproceedings {firm20,
    author = {Haoran Qiu and Subho S. Banerjee and Saurabh Jha and Zbigniew T. Kalbarczyk and Ravishankar K. Iyer},
    title = {{FIRM}: An Intelligent Fine-grained Resource Management Framework for {SLO-Oriented} Microservices},
    booktitle = {14th USENIX Symposium on Operating Systems Design and Implementation (OSDI 20)},
    year = {2020},
    isbn = {978-1-939133-19-9},
    pages = {805--825},
    url = {https://www.usenix.org/conference/osdi20/presentation/qiu},
    publisher = {USENIX Association},
    month = nov
}

@inproceedings{erlang24,
    author = {Sachidananda, Vighnesh and Sivaraman, Anirudh},
    title = {Erlang: Application-Aware Autoscaling for Cloud Microservices},
    year = {2024},
    isbn = {9798400704376},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3627703.3650084},
    doi = {10.1145/3627703.3650084},
    abstract = {As cloud applications shift from monoliths to loosely coupled microservices, application developers must decide how many compute resources (e.g., number of replicated containers) to assign to each microservice within an application. This decision affects both (1) the dollar cost to the application developer and (2) the end-to-end latency perceived by the application user. Today, individual microservices are autoscaled independently by adding VMs whenever per-microservice CPU or memory utilization crosses a configurable threshold. However, an application user's end-to-end latency consists of time spent on multiple microservices and each microservice might need a different number of VMs to achieve an overall end-to-end latency.We present Erlang, an autoscaler for microservice-based applications, which collectively allocates VMs to microservices with a global goal of minimizing dollar cost while keeping end-to-end application latency under a given target. Using 5 open-source applications, we compared Erlang to several utilization and machine learning based autoscalers. We evaluate Erlang across different compute settings on Google Kubernetes Engine (GKE) in which users manage compute resources, GKE standard, and a new mode of operation in which the cloud provider manages compute infrastructure, GKE Autopilot. Erlang meets a desired median or tail latency target on 53 of 63 workloads where it provides a cost reduction of 19.3\%, on average, over the next cheapest autoscaler. Erlang is the most cost effective autoscaling policy for 48 of these 53 workloads. The cost savings from managing a cluster with Erlang result in Erlang paying for its training cost in a few days. On smaller applications, for which we can exhaustively search microservice configurations, we find that Erlang is optimal for 90\% of cases and near optimal otherwise. Code for Erlang is available at https://github.com/vigsachi/erlang},
    booktitle = {Proceedings of the Nineteenth European Conference on Computer Systems},
    pages = {888–923},
    numpages = {36},
    location = {Athens, Greece},
    series = {EuroSys '24}
}

@inproceedings{needed23,
    author = {Christofidi, Georgia and Papaioannou, Konstantinos and Doudali, Thaleia Dimitra},
    title = {Is Machine Learning Necessary for Cloud Resource Usage Forecasting?},
    year = {2023},
    isbn = {9798400703874},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3620678.3624790},
    doi = {10.1145/3620678.3624790},
    abstract = {Robust forecasts of future resource usage in cloud computing environments enable high efficiency in resource management solutions, such as autoscaling and overcommitment policies. Production-level systems use lightweight combinations of historical information to enable practical deployments. Recently, Machine Learning (ML) models, in particular Long Short Term Memory (LSTM) neural networks, have been proposed by various works, for their improved predictive capabilities. Following this trend, we train LSTM models and observe high levels of prediction accuracy, even on unseen data. Upon meticulous visual inspection of the results, we notice that although the predicted values seem highly accurate, they are nothing but versions of the original data shifted by one time step into the future. Yet, this clear shift seems to be enough to produce a robust forecast, because the values are highly correlated across time. We investigate time series data of various resource usage metrics (CPU, memory, network, disk I/O) across different cloud providers and levels, such as at the physical or virtual machine-level and at the application job-level. We observe that resource utilization displays very small variations in consecutive time steps. This insight can enable very simple solutions, such as data shifts, to be used for cloud resource forecasting and deliver highly accurate predictions. This is the reason why we ask whether complex machine learning models are even necessary to use. We envision that practical resource management systems need to first identify the extent to which simple solutions can be effective, and resort to using machine learning to the extent that enables its practical use.},
    booktitle = {Proceedings of the 2023 ACM Symposium on Cloud Computing},
    pages = {544–554},
    numpages = {11},
    keywords = {Resource Usage, Prediction, Persistent Forecast, Machine Learning, Long Short Term Memory, Forecasting, Data Persistence, Cloud Computing},
    location = {Santa Cruz, CA, USA},
    series = {SoCC '23}
}

@inproceedings{sora23,
    author = {Liu, Jianshu and Wang, Qingyang and Zhang, Shungeng and Hu, Liting and Da Silva, Dilma},
    title = {Sora: A Latency Sensitive Approach for Microservice Soft Resource Adaptation},
    year = {2023},
    isbn = {9798400701771},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3590140.3592851},
    doi = {10.1145/3590140.3592851},
    abstract = {Fast response time for modern web services that include numerous distributed and lightweight microservices becomes increasingly important due to its business impact. While hardware-only resource scaling approaches (e.g., FIRM [47] and PARSLO [40]) have been proposed to mitigate response time fluctuations on critical microservices, the re-adaptation of soft resources (e.g., threads or connections) that control the concurrency of hardware resource usage has been largely ignored. This paper shows that the soft resource adaptation of critical microservices has a significant impact on system scalability because either under- or over-allocation of soft resources can lead to inefficient usage of underlying hardware resources. We present Sora, an intelligent, fast soft resource adaptation management framework for quickly identifying and adjusting the optimal concurrency level of critical microservices to mitigate service-level objective (SLO) violations. Sora leverages online fine-grained system metrics and the propagated deadline along the critical path of request execution to quickly and accurately provide optimal concurrency setting for critical microservices. Based on six real-world bursty workload traces and two representative microservices benchmarks (Sock Shop and Social Network), our experimental results show that Sora can effectively mitigate large response time fluctuations and reduce the 99th percentile latency by up to 2.5\texttimes{} compared to the hardware-only scaling strategy FIRM [47] and 1.5\texttimes{} to the state-of-the-art concurrency-aware system scaling strategy ConScale.},
    booktitle = {Proceedings of the 24th International Middleware Conference},
    pages = {43–56},
    numpages = {14},
    keywords = {Auto-scaling, Microservices, Scalability, Soft Resource},
    location = {Bologna, Italy},
    series = {Middleware '23}
}

@inproceedings {aware23,
    author = {Haoran Qiu and Weichao Mao and Chen Wang and Hubertus Franke and Alaa Youssef and Zbigniew T. Kalbarczyk and Tamer Ba{\c s}ar and Ravishankar K. Iyer},
    title = {{AWARE}: Automate Workload Autoscaling with Reinforcement Learning in Production Cloud Systems},
    booktitle = {2023 USENIX Annual Technical Conference (USENIX ATC 23)},
    year = {2023},
    isbn = {978-1-939133-35-9},
    address = {Boston, MA},
    pages = {387--402},
    url = {https://www.usenix.org/conference/atc23/presentation/qiu-haoran},
    publisher = {USENIX Association},
    month = jul
}

@inproceedings {towards23,
    author = {M. Fourati and S. Marzouk and M. Jmaiel},
    booktitle = {2023 IEEE Symposium on Computers and Communications (ISCC)},
    title = {Towards Microservices-Aware Autoscaling: A Review},
    year = {2023},
    volume = {},
    issn = {},
    pages = {1080-1083},
    abstract = {This research paper elaborates an overview of auto scaling solutions for microservices-based applications deployed with containers. Two main features may characterize the efficiency of an autoscaler: analysis strategy launched to identify the root cause of resource saturation, and resource allocation strategy which selects the eligible components for scaling and calculates the required amount of resources. However, existing solutions do not consider the specificity of microservice architecture in their analysis and resource allocation strategies, which may lead to wrong root cause identification and unnecessary resource allocation. In this paper, we investigate and classify existing autoscalers dealing with containers in microservice context. We additionally specify the strength and the shortcomings of each category. As a conclusion, we report the challenges of such solutions and provide recommendations for future works enabling the development of microservices-aware autoscalers.},
    keywords = {computers;microservice architectures;computer architecture;containers;dynamic scheduling;resource management},
    doi = {10.1109/ISCC58397.2023.10218213},
    url = {https://doi.ieeecomputersociety.org/10.1109/ISCC58397.2023.10218213},
    publisher = {IEEE Computer Society},
    address = {Los Alamitos, CA, USA},
    month = {jul}
}
@inproceedings{microscaler19,
    author={Yu, Guangba and Chen, Pengfei and Zheng, Zibin},
    booktitle={2019 IEEE International Conference on Web Services (ICWS)}, 
    title={Microscaler: Automatic Scaling for Microservices with an Online Learning Approach}, 
    year={2019},
    volume={},
    number={},
    pages={68-75},
    keywords={Auto-scaling;Micro service;Service Mesh;Bayesian Optimization;Cloud computing},
    doi={10.1109/ICWS.2019.00023}
}
@article{hpa20,
    AUTHOR = {Nguyen, Thanh-Tung and Yeom, Yu-Jin and Kim, Taehong and Park, Dae-Heon and Kim, Sehan},
    TITLE = {Horizontal Pod Autoscaling in Kubernetes for Elastic Container Orchestration},
    JOURNAL = {Sensors},
    VOLUME = {20},
    YEAR = {2020},
    NUMBER = {16},
    ARTICLE-NUMBER = {4621},
    URL = {https://www.mdpi.com/1424-8220/20/16/4621},
    PubMedID = {32824508},
    ISSN = {1424-8220},
    ABSTRACT = {Kubernetes, an open-source container orchestration platform, enables high availability and scalability through diverse autoscaling mechanisms such as Horizontal Pod Autoscaler (HPA), Vertical Pod Autoscaler and Cluster Autoscaler. Amongst them, HPA helps provide seamless service by dynamically scaling up and down the number of resource units, called pods, without having to restart the whole system. Kubernetes monitors default Resource Metrics including CPU and memory usage of host machines and their pods. On the other hand, Custom Metrics, provided by external software such as Prometheus, are customizable to monitor a wide collection of metrics. In this paper, we investigate HPA through diverse experiments to provide critical knowledge on its operational behaviors. We also discuss the essential difference between Kubernetes Resource Metrics (KRM) and Prometheus Custom Metrics (PCM) and how they affect HPA’s performance. Lastly, we provide deeper insights and lessons on how to optimize the performance of HPA for researchers, developers, and system administrators working with Kubernetes in the future.},
    DOI = {10.3390/s20164621}
}
@inproceedings {tracemesh24,
    author = { Chen, Zhuangbin and Jiang, Zhihan and Su, Yuxin and Lyu, Michael R. and Zheng, Zibin },
    booktitle = { 2024 IEEE 17th International Conference on Cloud Computing (CLOUD) },
    title = {{ Tracemesh: Scalable and Streaming Sampling for Distribuauthor={Otero, Manuel and Garcia, Jose María and Fernandez, Pablo},
    booktitle={2024 IEEE 44th International Conference on Distributed Computing Systems Workshops (ICDCSW)}, 
    title={Towards a lightweight distributed telemetry for microservices}, 
    year={2024},
    volume={},
    number={},
    pages={75-82},
    keywords={Root cause analysis;Biological system modeling;System performance;Ecosystems;Microservice architectures;Computer architecture;User interfaces;telemetry;oas;api;microservices},
    doi={10.1109/ICDCSW63686.2024.00018}ted Traces }},
    year = {2024},
    volume = {},
    ISSN = {},
    pages = {54-65},
    abstract = { Distributed tracing serves as a fundamental element in the monitoring of cloud-based and datacenter systems. It provides visibility into the full life cycle of a request or operation across multiple services, which is essential for understanding system dependencies and performance bottlenecks. To mitigate computational and storage overheads, most tracing frameworks adopt a uniform sampling strategy, which inevitably captures overlapping and redundant information. More advanced methods employ learning-based approaches to bias the sampling toward more informative traces. However, existing methods fall short of considering the high-dimensional and dynamic nature of trace data, which is essential for the production deployment of trace sampling. To address these practical challenges, in this paper we present Trace Mesh,a scalable and streaming sampler for distributed traces. Tracemesh employs Locality-Sensitivity Hashing (LSH) to improve sampling efficiency by projecting traces into a low-dimensional space while preserving their similarity. In this process, Tracemesh accommodates previously unseen trace features in a unified and streamlined way. Subsequently, Tracemesh samples traces through evolving clustering, which dynamically adjusts the sampling decision to avoid over-sampling of recurring traces. The proposed method is evaluated with trace data collected from both open-source microservice benchmarks and production service systems. Ex-perimental results demonstrate that Tracemesh outperforms state-of-the-art methods by a significant margin in both sampling accuracy and efficiency. },
    keywords = {Cloud computing;Production systems;Microservice architectures;Benchmark testing;Aerodynamics;Vectors;Encoding},
    doi = {10.1109/CLOUD62652.2024.00016},
    url = {https://doi.ieeecomputersociety.org/10.1109/CLOUD62652.2024.00016},
    publisher = {IEEE Computer Society},
    address = {Los Alamitos, CA, USA},
    month = Jul
}
@inproceedings{sifter19,
    author = {Las-Casas, Pedro and Papakerashvili, Giorgi and Anand, Vaastav and Mace, Jonathan},
    title = {Sifter: Scalable Sampling for Distributed Traces, without Feature Engineering},
    year = {2019},
    isbn = {9781450369732},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3357223.3362736},
    doi = {10.1145/3357223.3362736},
    abstract = {Distributed tracing is a core component of cloud and datacenter systems, and provides visibility into their end-to-end runtime behavior. To reduce computational and storage overheads, most tracing frameworks do not keep all traces, but sample them uniformly at random. While effective at reducing overheads, uniform random sampling inevitably captures redundant, common-case execution traces, which are less useful for analysis and troubleshooting tasks. In this work we present Sifter, a general-purpose framework for biased trace sampling. Sifter captures qualitatively more diverse traces, by weighting sampling decisions towards edge-case code paths, infrequent request types, and anomalous events. Sifter does so by using the incoming stream of traces to build an unbiased low-dimensional model that approximates the system's common-case behavior. Sifter then biases sampling decisions towards traces that are poorly captured by this model. We have implemented Sifter, integrated it with several open-source tracing systems, and evaluate with traces from a range of open-source and production distributed systems. Our evaluation shows that Sifter effectively biases towards anomalous and outlier executions, is robust to noisy and heterogeneous traces, is efficient and scalable, and adapts to changes in workloads over time.},
    booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
    pages = {312–324},
    numpages = {13},
    location = {Santa Cruz, CA, USA},
    series = {SoCC '19}
}
@inproceedings{sieve21,
    author={Huang, Zicheng and Chen, Pengfei and Yu, Guangba and Chen, Hongyang and Zheng, Zibin},
    booktitle={2021 IEEE International Conference on Web Services (ICWS)}, 
    title={Sieve: Attention-based Sampling of End-to-End Trace Data in Distributed Microservice Systems}, 
    year={2021},
    volume={},
    number={},
    pages={436-446},
    keywords={Web services;Conferences;Redundancy;Distributed databases;Forestry;Real-time systems;Monitoring;End-to-end tracing;Weighted sampling;Microservice;Robust Random Cut Forest},
    doi={10.1109/ICWS53863.2021.00063}
}
@inproceedings{streamspot16,
    author = {Manzoor, Emaad and Milajerdi, Sadegh M. and Akoglu, Leman},
    title = {Fast Memory-efficient Anomaly Detection in Streaming Heterogeneous Graphs},
    year = {2016},
    isbn = {9781450342322},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2939672.2939783},
    doi = {10.1145/2939672.2939783},
    abstract = {Given a stream of heterogeneous graphs containing different types of nodes and edges, how can we spot anomalous ones in real-time while consuming bounded memory? This problem is motivated by and generalizes from its application in security to host-level advanced persistent threat (APT) detection. We propose StreamSpot, a clustering based anomaly detection approach that addresses challenges in two key fronts: (1) heterogeneity, and (2) streaming nature. We introduce a new similarity function for heterogeneous graphs that compares two graphs based on their relative frequency of local substructures, represented as short strings. This function lends itself to a vector representation of a graph, which is (a) fast to compute, and (b) amenable to a sketched version with bounded size that preserves similarity.StreamSpot exhibits desirable properties that a streaming application requires: it is (i) fully-streaming; processing the stream one edge at a time as it arrives, (ii) memory-efficient; requiring constant space for the sketches and the clustering, (iii) fast; taking constant time to update the graph sketches and the cluster summaries that can process over 100,000 edges per second, and (iv) online; scoring and flagging anomalies in real time. Experiments on datasets containing simulated system-call flow graphs from normal browser activity and various attack scenarios (ground truth) show that StreamSpot is high-performance; achieving above 95\% detection accuracy with small delay, as well as competitive time and memory usage.},
    booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
    pages = {1035–1044},
    numpages = {10},
    keywords = {typed graphs, temporal networks, streamspot, heterogenous graphs, graph sketches, evolving graphs, dynamic networks, anomaly detection},
    location = {San Francisco, California, USA},
    series = {KDD '16}
}
@inproceedings{tolightweight24,
    author={Otero, Manuel and Garcia, Jose María and Fernandez, Pablo},
    booktitle={2024 IEEE 44th International Conference on Distributed Computing Systems Workshops (ICDCSW)}, 
    title={Towards a lightweight distributed telemetry for microservices}, 
    year={2024},
    volume={},
    number={},
    pages={75-82},
    keywords={Root cause analysis;Biological system modeling;System performance;Ecosystems;Microservice architectures;Computer architecture;User interfaces;telemetry;oas;api;microservices},
    doi={10.1109/ICDCSW63686.2024.00018}
}
@inproceedings{nezha23,
    author = {Yu, Guangba and Chen, Pengfei and Li, Yufeng and Chen, Hongyang and Li, Xiaoyun and Zheng, Zibin},
    title = {Nezha: Interpretable Fine-Grained Root Causes Analysis for Microservices on Multi-modal Observability Data},
    year = {2023},
    isbn = {9798400703270},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3611643.3616249},
    doi = {10.1145/3611643.3616249},
    abstract = {Root cause analysis (RCA) in large-scale microservice systems is a critical and challenging task.  
    To understand and localize root causes of unexpected faults, modern observability tools collect and preserve multi-modal observability data, including metrics, traces, and logs. Since system faults may manifest as anomalies in different data sources, existing RCA approaches that rely on single-modal data are constrained in the granularity and interpretability of root causes. In this study, we present Nezha, an interpretable and fine-grained RCA approach that pinpoints root causes at the code region and resource type level by incorporative analysis of multi-modal data. Nezha transforms heterogeneous multi-modal data into a homogeneous event representation and extracts event patterns by constructing and mining event graphs. The core idea of Nezha is to compare event patterns in the fault-free phase with those in the fault-suffering phase to localize root causes in an interpretable way. Practical implementation and experimental evaluations on two microservice applications show that Nezha achieves a high top1 accuracy (89.77\%) on average at the code region and resource type level and outperforms state-of-the-art approaches by a large margin. Two ablation studies further confirm the contributions of incorporating multi-modal data.},
    booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
    pages = {553–565},
    numpages = {13},
    keywords = {Microservice, Multi-modal Observability Data, Root Cause Analysis},
    location = {San Francisco, CA, USA},
    series = {ESEC/FSE 2023}
}
@inproceedings{toefficient24,
    author = {Belkhiri, Adel and Ben Attia, Maroua and Gohring De Magalhaes, Felipe and Nicolescu, Gabriela},
    title = {Towards Efficient Diagnosis of Performance Bottlenecks in Microservice-Based Applications (Work In Progress paper)},
    year = {2024},
    isbn = {9798400704451},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3629527.3651432},
    doi = {10.1145/3629527.3651432},
    abstract = {Microservices have been a cornerstone for building scalable, flexible, and robust applications, thereby enabling service providers to enhance their systems' resilience and fault tolerance. However, adopting this architecture has often led to many challenges, particularly when pinpointing performance bottlenecks and diagnosing their underlying causes. Various tools have been developed to bridge this gap and facilitate comprehensive observability in microservice ecosystems. While these tools are effective at detecting latency-related anomalies, they often fall short of isolating the root causes of these problems. In this paper, we present a novel method for identifying and analyzing performance anomalies in microservice-based applications by leveraging cross-layer tracing techniques. Our method uniquely integrates system resource metrics-such as CPU, disk, and network consumption-with each user request, providing a multi-dimensional view for diagnosing performance issues. Through the use of sequential pattern mining, this method effectively isolates aberrant execution behaviors and helps identify their root causes. Our experimental evaluations demonstrate its efficiency in diagnosing a wide range of performance anomalies.},
    booktitle = {Companion of the 15th ACM/SPEC International Conference on Performance Engineering},
    pages = {40–46},
    numpages = {7},
    keywords = {distributed systems, microservices, performance analysis, software tracing},
    location = {London, United Kingdom},
    series = {ICPE '24 Companion}
}
@inproceedings{transparent23,
    author = {Belkhiri, Adel and Shahnejat Bushehri, Ahmad and Gohring de Magalhaes, Felipe and Nicolescu, Gabriela},
    title = {Transparent Trace Annotation for Performance Debugging in Microservice-oriented Systems (Work In Progress Paper)},
    year = {2023},
    isbn = {9798400700729},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3578245.3585030},
    doi = {10.1145/3578245.3585030},
    abstract = {Microservices is a cloud-native architecture in which a single application is implemented as a collection of small, independent, and loosely-coupled services. This architecture is gaining popularity in the industry as it promises to make applications more scalable and easier to develop and deploy. Nonetheless, adopting this architecture in practice has raised many concerns, particularly regarding the difficulty of diagnosing performance bugs and explaining abnormal software behaviour. Fortunately, many tools based on distributed tracing were proposed to achieve observability in microservice-oriented systems and address these concerns (e.g., Jaeger). Distributed tracing is a method for tracking user requests as they flow between services. While these tools can identify slow services and detect latency-related problems, they mostly fail to pinpoint the root causes of these issues.This paper presents a new approach for enacting cross-layer tracing of microservice-based applications. It also proposes a framework for annotating traces generated by most distributed tracing tools with relevant tracing data and metrics collected from the kernel. The information added to the traces aims at helping the practitioner get a clear insight into the operations of the application executing user requests. The framework we present is notably efficient in diagnosing the causes of long tail latencies. Unlike other solutions, our approach for annotating traces is completely transparent as it does not require the modification of the application, the tracer, or the operating system. Furthermore, our evaluation shows that this approach incurs low overhead costs.},
    booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
    pages = {25–32},
    numpages = {8},
    keywords = {distributed systems, microservices, performance analysis, software tracing},
    location = {Coimbra, Portugal},
    series = {ICPE '23 Companion}
}
@inproceedings{tprof21,
    author = {Huang, Lexiang and Zhu, Timothy},
    title = {tprof: Performance profiling via structural aggregation and automated analysis of distributed systems traces},
    year = {2021},
    isbn = {9781450386388},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3472883.3486994},
    doi = {10.1145/3472883.3486994},
    abstract = {The traditional approach for performance debugging relies upon performance profilers (e.g., gprof, VTune) that provide average function runtime information. These aggregate statistics help identify slow regions affecting the entire workload, but they are ill-suited for identifying slow regions that only impact a fraction of the workload, such as tail latency effects. This paper takes a new approach to performance profiling by utilizing distributed tracing systems (e.g., Dapper, Zipkin, Jaeger). Since traces provide detailed timing information on a per-request basis, it is possible to group and aggregate tracing data in many different ways to identify the slow parts of the system. Our new approach to trace aggregation uses the structure embedded within traces to hierarchically group similar traces and calculate increasingly detailed aggregate statistics based on how the traces are grouped. We also develop an automated tool for analyzing the hierarchy of statistics to identify the most likely performance issues. Our case study across two complex distributed systems illustrates how our tool is able to find multiple performance issues that lead to 10x and 28x performance improvements in terms of average and tail latency, respectively. Our comparison with a state-of-the-art industry tool shows that our tool can pinpoint performance slowdowns more accurately than current approaches.},
    booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
    pages = {76–91},
    numpages = {16},
    keywords = {performance debugging, distributed systems tracing},
    location = {Seattle, WA, USA},
    series = {SoCC '21}
}
@online{otel24,
    author = {OpenTelemetry},
    title = {OpenTelemetry},
    year = 2024,
    url = {https://opentelemetry.io/},
    urldate = {2024-10-25}
}
@online{tempo24,
    author = {Grafana},
    title = {Grafana Tempo OSS: Distributed tracing backend},
    year = 2024,
    url = {https://grafana.com/oss/tempo/},
    urldate = {2024-10-25}
}
@online{zipkin24,
    author = {Zipkin},
    title = {OpenZipkin: A distributed tracing system},
    year = 2024,
    url = {https://zipkin.io/},
    urldate = {2024-12-08}
}
@online{jaeger24,
    author = {Zipkin},
    title = {Jaeger: open source, distributed tracing platform},
    year = 2024,
    url = {https://www.jaegertracing.io/},
    urldate = {2024-12-08}
}
@online{skywalking24,
    author = {Zipkin},
    title = {Apache SkyWalking},
    year = 2024,
    url = {https://skywalking.apache.org/},
    urldate = {2024-12-08}
}
@online{minikube24,
    author = {Minikube},
    title = {Minikube},
    year = 2024,
    url = {https://minikube.sigs.k8s.io/},
    urldate = {2024-10-26}
}@online{river24,
    author = {River},
    title = {River},
    year = 2024,
    url = {https://riverml.xyz/dev/},
    urldate = {2024-11-15}
}
@inproceedings{streamhash16,
    author = {Manzoor, Emaad and Milajerdi, Sadegh M. and Akoglu, Leman},
    title = {Fast Memory-efficient Anomaly Detection in Streaming Heterogeneous Graphs},
    year = {2016},
    isbn = {9781450342322},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2939672.2939783},
    doi = {10.1145/2939672.2939783},
    abstract = {Given a stream of heterogeneous graphs containing different types of nodes and edges, how can we spot anomalous ones in real-time while consuming bounded memory? This problem is motivated by and generalizes from its application in security to host-level advanced persistent threat (APT) detection. We propose StreamSpot, a clustering based anomaly detection approach that addresses challenges in two key fronts: (1) heterogeneity, and (2) streaming nature. We introduce a new similarity function for heterogeneous graphs that compares two graphs based on their relative frequency of local substructures, represented as short strings. This function lends itself to a vector representation of a graph, which is (a) fast to compute, and (b) amenable to a sketched version with bounded size that preserves similarity.StreamSpot exhibits desirable properties that a streaming application requires: it is (i) fully-streaming; processing the stream one edge at a time as it arrives, (ii) memory-efficient; requiring constant space for the sketches and the clustering, (iii) fast; taking constant time to update the graph sketches and the cluster summaries that can process over 100,000 edges per second, and (iv) online; scoring and flagging anomalies in real time. Experiments on datasets containing simulated system-call flow graphs from normal browser activity and various attack scenarios (ground truth) show that StreamSpot is high-performance; achieving above 95\% detection accuracy with small delay, as well as competitive time and memory usage.},
    booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
    pages = {1035–1044},
    numpages = {10},
    keywords = {anomaly detection, dynamic networks, evolving graphs, graph sketches, heterogenous graphs, streamspot, temporal networks, typed graphs},
    location = {San Francisco, California, USA},
    series = {KDD '16}
}
@inbook{denstream06,
    author = {Feng Cao and Martin Estert and Weining Qian and Aoying Zhou},
    title = {Density-Based Clustering over an Evolving Data Stream with Noise},
    booktitle = {Proceedings of the 2006 SIAM International Conference on Data Mining (SDM)},
    chapter = {},
    year = {2006},
    pages = {328-339},
    doi = {10.1137/1.9781611972764.29},
    URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611972764.29},
    eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611972764.29},
    abstract = { Abstract Clustering is an important task in mining evolving data streams. Beside the limited memory and one-pass constraints, the nature of evolving data streams implies the following requirements for stream clustering: no assumption on the number of clusters, discovery of clusters with arbitrary shape and ability to handle outliers. While a lot of clustering algorithms for data streams have been proposed, they offer no solution to the combination of these requirements. In this paper, we present DenStream, a new approach for discovering clusters in an evolving data stream. The “dense” micro-cluster (named core-micro-cluster) is introduced to summarize the clusters with arbitrary shape, while the potential core-micro-cluster and outlier micro-cluster structures are proposed to maintain and distinguish the potential clusters and outliers. A novel pruning strategy is designed based on these concepts, which guarantees the precision of the weights of the micro-clusters with limited memory. Our performance study over a number of real and synthetic data sets demonstrates the effectiveness and efficiency of our method. }
}
@inproceedings{weighted18,
    author = {Las-Casas, Pedro and Mace, Jonathan and Guedes, Dorgival and Fonseca, Rodrigo},
    title = {Weighted Sampling of Execution Traces: Capturing More Needles and Less Hay},
    year = {2018},
    isbn = {9781450360111},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3267809.3267841},
    doi = {10.1145/3267809.3267841},
    abstract = {End-to-end tracing has emerged recently as a valuable tool to improve the dependability of distributed systems, by performing dynamic verification and diagnosing correctness and performance problems. Contrary to logging, end-to-end traces enable coherent sampling of the entire execution of specific requests, and this is exploited by many deployments to reduce the overhead and storage requirements of tracing. This sampling, however, is usually done uniformly at random, which dedicates a large fraction of the sampling budget to common, 'normal' executions, while missing infrequent, but sometimes important, erroneous or anomalous executions. In this paper we define the representative trace sampling problem, and present a new approach, based on clustering of execution graphs, that is able to bias the sampling of requests to maximize the diversity of execution traces stored towards infrequent patterns. In a preliminary, but encouraging work, we show how our approach chooses to persist representative and diverse executions, even when anomalous ones are very infrequent.},
    booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
    pages = {326–332},
    numpages = {7},
    keywords = {weighted sampling, distributed tracing},
    location = {Carlsbad, CA, USA},
    series = {SoCC '18}
}
@inproceedings{sketchgraph23,
    author = {Bhatia, Siddharth and Wadhwa, Mohit and Kawaguchi, Kenji and Shah, Neil and Yu, Philip S. and Hooi, Bryan},
    title = {Sketch-Based Anomaly Detection in Streaming Graphs},
    year = {2023},
    isbn = {9798400701030},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3580305.3599504},
    doi = {10.1145/3580305.3599504},
    abstract = {Given a stream of graph edges from a dynamic graph, how can we assign anomaly scores to edges and subgraphs in an online manner, for the purpose of detecting unusual behavior, using constant time and memory? For example, in intrusion detection, existing work seeks to detect either anomalous edges or anomalous subgraphs, but not both. In this paper, we first extend the count-min sketch data structure to a higher-order sketch. This higher-order sketch has the useful property of preserving the dense subgraph structure (dense subgraphs in the input turn into dense submatrices in the data structure). We then propose 4 online algorithms that utilize this enhanced data structure, which (a) detect both edge and graph anomalies; (b) process each edge and graph in constant memory and constant update time per newly arriving edge, and; (c) outperform state-of-the-art baselines on 4 real-world datasets. Our method is the first streaming approach that incorporates dense subgraph search to detect graph anomalies in constant memory and time.},
    booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
    pages = {93–104},
    numpages = {12},
    keywords = {stream, sketch, dynamic graphs, anomaly detection},
    location = {Long Beach, CA, USA},
    series = {KDD '23}
}
@inproceedings{unsupanomaly20,
    author={Liu, Ping and Xu, Haowen and Ouyang, Qianyu and Jiao, Rui and Chen, Zhekang and Zhang, Shenglin and Yang, Jiahai and Mo, Linlin and Zeng, Jice and Xue, Wenman and Pei, Dan},
    booktitle={2020 IEEE 31st International Symposium on Software Reliability Engineering (ISSRE)}, 
    title={Unsupervised Detection of Microservice Trace Anomalies through Service-Level Deep Bayesian Networks}, 
    year={2020},
    volume={},
    number={},
    pages={48-58},
    keywords={Training;Companies;Software;Bayes methods;Software reliability;Time factors;Anomaly detection;trace;anomaly detection;microservice},
    doi={10.1109/ISSRE5003.2020.00014}
}
@inproceedings{gtrace23,
    author = {Xie, Zhe and Pei, Changhua and Li, Wanxue and Jiang, Huai and Su, Liangfei and Li, Jianhui and Xie, Gaogang and Pei, Dan},
    title = {From Point-wise to Group-wise: A Fast and Accurate Microservice Trace Anomaly Detection Approach},
    year = {2023},
    isbn = {9798400703270},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3611643.3613861},
    doi = {10.1145/3611643.3613861},
    abstract = {As Internet applications continue to scale up, microservice architecture has become increasingly popular due to its flexibility and logical structure. Anomaly detection in traces that record inter-microservice invocations is essential for diagnosing system failures. Deep learning-based approaches allow for accurate modeling of structural features (i.e., call paths) and latency features (i.e., call response time), which can determine the anomaly of a particular trace sample. However, the point-wise manner employed by these methods results in substantial system detection overhead and impracticality, given the massive volume of traces (billion-level). Furthermore, the point-wise approach lacks high-level information, as identical sub-structures across multiple traces may be encoded differently. In this paper, we introduce the first Group-wise Trace anomaly detection algorithm, named GTrace. This method categorizes the traces into distinct groups based on their shared sub-structure, such as the entire tree or sub-tree structure. A group-wise Variational AutoEncoder (VAE) is then employed to obtain structural representations. Moreover, the innovative "predicting latency with structure" learning paradigm facilitates the association between the grouped structure and the latency distribution within each group. With the group-wise design, representation caching, and batched inference strategies can be implemented, which significantly reduces the burden of detection on the system. Our comprehensive evaluation reveals that GTrace outperforms state-of-the-art methods in both performances (2.64\% to 195.45\% improvement in AUC metrics and 2.31\% to 40.92\% improvement in best F-Score) and efficiency (21.9x to 28.2x speedup). We have deployed and assessed the proposed algorithm on eBay's microservices cluster, and our code is available at https://github.com/NetManAIOps/GTrace.git.},
    booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
    pages = {1739–1749},
    numpages = {11},
    keywords = {anomaly detection, microservice trace, variational autoencoder},
    location = {San Francisco, CA, USA},
    series = {ESEC/FSE 2023}
}
@inproceedings{hst11,
    author = {Tan, Swee Chuan and Ting, Kai Ming and Liu, Tony Fei},
    title = {Fast anomaly detection for streaming data},
    year = {2011},
    isbn = {9781577355144},
    publisher = {AAAI Press},
    abstract = {This paper introduces Streaming Half-Space-Trees (HS-Trees), a fast one-class anomaly detector for evolving data streams. It requires only normal data for training and works well when anomalous data are rare. The model features an ensemble of random HS-Trees, and the tree structure is constructed without any data. This makes the method highly efficient because it requires no model restructuring when adapting to evolving data streams. Our analysis shows that Streaming HS-Trees has constant amortised time complexity and constant memory requirement. When compared with a state-of-the-art method, our method performs favourably in terms of detection accuracy and runtime performance. Our experimental results also show that the detection performance of Streaming HS-Trees is not sensitive to its parameter settings.},
    booktitle = {Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence - Volume Volume Two},
    pages = {1511–1516},
    numpages = {6},
    location = {Barcelona, Catalonia, Spain},
    series = {IJCAI'11}
}